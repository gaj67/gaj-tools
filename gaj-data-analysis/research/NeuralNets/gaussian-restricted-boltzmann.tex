\documentclass[a4paper]{article}
\usepackage{graphicx,subcaption}
\usepackage{amsmath,amsfonts}
\usepackage{amssymb}
\usepackage{accents}

\newcommand{\rvec}[1]{\accentset{\leftarrow}{#1}}
\newcommand{\v}[1]{\mathbf{#1}}

\title{Gaussian Restricted Boltzmann Classifier}
\author{G.A. Jarrad}

\begin{document}
\maketitle
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}
\section{Definition}\label{sec:intro}
Consider a restricted Boltzmann machine (RBM) with a Gaussian input layer,
a Bernoulli hidden layer, and a multinomial output layer, as shown in 
Figure~\ref{fig:rbm}.
The energy function is given by
\begin{eqnarray}
    E(\v{x},\v{h},\v{y}; \Theta) & = & \frac{1}{2}\|\v{x}-\v{a}\|^2
    - \v{b}^T\v{h} - \v{h}^T W\v{x} - \v{c}^T\v{y} - \v{h}^T U\v{y}\,,
\end{eqnarray}
with input feature vector $\v{x}=(x_1,x_2,\ldots,x_F)\in\mathbb{X}\subsete\mathbb{R}^F$, 
hidden binary vector $\v{h}=(h_1,h_2,\ldots,h_H)\in\mathbb{H}=\{0,1\}^H$, and output 
one-of-$C$ vector 
$\v{y}=(y_1,y_2,\ldots,y_C)\in\mathbb{Y}=\{0,1\}^C$
satisfying $\sum_{k=1}^C y_k=1$.
The model parameters are $\Theta=(\v{a}, \v{b}, \v{c}, W, U)$.
Note that for convenience we may switch between vector-valued $\v{y}$
and scalar-valued $y\in\{1,2,\ldots,C\}$ as needed, where $y=k \Leftrightarrow y_k=1$.

The joint probability of $\v{x}$, $\v{y}$ and $\v{h}$ is then
\begin{eqnarray}
    p(\v{x},\v{h},\v{y}\;|\;\Theta) & = & \frac{e^{-E(\v{x},\v{h},\v{y}; \Theta)}}{Z(\Theta)}
\nonumber\\&=&
\frac{
    \exp{-\frac{1}{2}\|\v{x}-\v{a}\|^2+\v{b}^T\v{h}+\v{h}^T W\v{x}+\v{c}^T\v{y}+\v{h}^T U\v{y}}
}
{\int_{\mathbb{X}}\sum_{\v{h}'\in\mathbb{H}}\sum_{\v{y}'\in\mathbb{Y}}
   \exp{-\frac{1}{2}\|\v{x}'-\v{a}\|^2+\v{b}^T\v{h}'+\v{h}'^T W\v{x}'+\v{c}^T\v{y}'+\v{h}^T U\v{y}'}
   \,d|\v{x}'|
}\,.
\end{eqnarray}
Now, the bipartite restriction shown in Figure~\ref{fig:rbm} ensures that $\v{x}$ and $\v{y}$
are conditionally independent given $\v{h}$.
Hence, we deduce for all $\v{y}\in\mathbb{Y}$ that
\begin{eqnarray}
    p(\v{x}\;|\;\v{h},\Theta) & = & p(\v{x}\;|\;\v{h},\v{y},\Theta)
    ~=~\frac{p(\v{x},\v{h},\v{y}\;|\;\Theta)}{p(\v{h},\v{y}\;|\;\Theta)}
\nonumber\\&=&
\frac{
    \exp{-\frac{1}{2}\|\v{x}-\v{a}\|^2+\v{b}^T\v{h}+\v{h}^T W\v{x}+\v{c}^T\v{y}+\v{h}^T U\v{y}}
}
{
    \int_{\mathbb{X}}
    \exp{-\frac{1}{2}\|\v{x}'-\v{a}\|^2+\v{b}^T\v{h}+\v{h}^T W\v{x}'+\v{c}^T\v{y}+\v{h}^T U\v{y}}
    \,d|\v{x}'|
}
\nonumber\\&=&
\frac{
    \exp{-\frac{1}{2}\|\v{x}-\v{a}\|^2+\v{h}^T W\v{x}}
}
{
    \int_{\mathbb{X}}\exp{-\frac{1}{2}\|\v{x}'-\v{a}\|^2+\v{h}^T W\v{x}'}\,d|\v{x}'|
}
\nonumber\\&=&
\frac{
    \exp{-\frac{1}{2}\|\v{x}-\v{a}-W^T\v{h}\|^2+\v{h}^T W\v{a}+\frac{1}{2}\v{h}^T WW^T \v{h}}
}
{
    \int_{\mathbb{X}}
    \exp{-\frac{1}{2}\|\v{x}-\v{a}-W^T\v{h}\|^2+\v{h}^T W\v{a}+\frac{1}{2}\v{h}^T WW^T \v{h}}
    \,d|\v{x}'|
}
\nonumber\\&=&
\frac{
    \exp{-\frac{1}{2}\|\v{x}-\v{a}-W^T\v{h}\|^2}
}
{
    \int_{\mathbb{X}}\exp{-\frac{1}{2}\|\v{x}-\v{a}-W^T\v{h}\|^2}\,d|\v{x}'|
}
\nonumber\\&=& N(\v{x}\;|\;\v{a}+W^T\v{h},I)\,.
\end{eqnarray}
Thus, $\v{x}|\v{h}$ is normally distributed with mean $\v{a}+W^T\v{h}$ and unit spherical 
variance $I$ (the identity matrix).

Similarly, for all $\v{x}\in\mathbb{X}$ observe that
\begin{eqnarray}
    p(\v{y}\;|\;\v{h},\Theta) & = & p(\v{y}\;|\;\v{x},\v{h},\Theta)
    ~=~\frac{p(\v{x},\v{h},\v{y}\;|\;\Theta)}{p(\v{x},\v{h}\;|\;\Theta)}
\nonumber\\&=&
\frac{
    \exp{-\frac{1}{2}\|\v{x}-\v{a}\|^2+\v{b}^T\v{h}+\v{h}^T W\v{x}+\v{c}^T\v{y}+\v{h}^T U\v{y}}
}
{
    \sum_{\v{y}'\in\mathbb{Y}}
    \exp{-\frac{1}{2}\|\v{x}-\v{a}\|^2+\v{b}^T\v{h}+\v{h}^T W\v{x}+\v{c}^T\v{y}'+\v{h}^T U\v{y}'}
}
\nonumber\\&=&
\frac{
    \exp{\v{c}^T\v{y}+\v{h}^T U\v{y}}
}
{
    \sum_{\v{y}'\in\mathbb{Y}}
    \exp{\v{c}^T\v{y}'+\v{h}^T U\v{y}'}
}
\,,
\end{eqnarray}
and so
\begin{eqnarray}
  p(y\;|\;\v{h},\Theta) & = & \frac{e^{c_y+\v{h}^T\v{u}_y}}
  {\sum_{y'=1}^{C}e^{(c_{y'}+\v{h}^T \v{u}_{y'}}}\,,
\end{eqnarray}
where $\v{u}_y$ is the $y$-th column of $U$.
This result is just the {\em soft-max} function, or logistic classifier.

Conversely, $\v{h}$ depends upon both $\v{x}$ and $\v{y}$ via
\begin{eqnarray}
    p(\v{h}\;|\;\v{x},\v{y},\Theta) & = & 
    \frac{p(\v{x},\v{h},\v{y}\;|\;\Theta)}{p(\v{x},\v{y}\;|\;\Theta)}
\nonumber\\&=&
\frac{
    \exp{-\frac{1}{2}\|\v{x}-\v{a}\|^2+\v{b}^T\v{h}+\v{h}^T W\v{x}+\v{c}^T\v{y}+\v{h}^T U\v{y}}
}
{
    \sum_{\v{h}'\in\mathbb{H}}
    \exp{-\frac{1}{2}\|\v{x}-\v{a}\|^2+\v{b}^T\v{h}'+\v{h}'^T W\v{x}+\v{c}^T\v{y}+\v{h}'^T U\v{y}}
}
\nonumber\\&=&
\frac{
    \exp{\v{b}^T\v{h}+\v{h}^T W\v{x}+\v{h}^T\v{u}_y}
}
{
    \sum_{\v{h}'\in\mathbb{H}}
    \exp{\v{b}^T\v{h}'+\v{h}'^T W\v{x}+\v{h}'^T\v{u}_y}
}
\nonumber\\&=&
\frac{
    \prod_{i=1}^H\exp{b_i h_i'+h_i \v{w}_i^T\v{x}+h_i U_{iy}}
}
{
    \prod_{i=1}^H\sum_{h_i'=0}^{1}
    \exp{b_i h_i'+h_i' \v{w}_i^T\v{x}+h_i' U_{iy}}
}
\,,
\end{eqnarray}
where $\v{w}_i^T$ is the $i$-th row of $W$.
Hence
\begin{eqnarray}
    p(\v{h}\;|\;\v{x},y,\Theta) & = & \prod_{i=1}^H p(h_i\;|\;\v{x},y,\Theta)
\,,
\end{eqnarray}
where 
\begin{eqnarray}
  p(h_i=0\;|\;\v{x},y,\Theta) & = & 
  \frac{1}{1+e^{b_i+\v{w}_i^T\v{x}+U_{iy}}}
  \,.
\end{eqnarray}
This is just the complement of the logistic sigmoid function.

Finally, observe that
\begin{eqnarray}
  p(\v{y}\;|\;\v{x},\Theta) & = & \sum_{\v{h}'\in\mathbb{H}}p(\v{y},\v{h}'\;|\;\v{x},\Theta)
\nonumber\\&=&
\frac{
    \sum_{\v{h}'\in\mathbb{H}}
    \exp{-\frac{1}{2}\|\v{x}-\v{a}\|^2+\v{b}^T\v{h}'+\v{h}'^T W\v{x}+\v{c}^T\v{y}+\v{h}'^T U\v{y}}
}
{
    \sum_{\v{y}'\in\mathbb{Y}}
    \sum_{\v{h}'\in\mathbb{H}}
    \exp{-\frac{1}{2}\|\v{x}-\v{a}\|^2+\v{b}^T\v{h}'+\v{h}'^T W\v{x}+\v{c}^T\v{y}'+\v{h}'^T U\v{y}'}
}
\nonumber\\&=&
\frac{
    \sum_{\v{h}'\in\mathbb{H}}
    \exp{\v{b}^T\v{h}'+\v{h}'^T W\v{x}+\v{c}^T\v{y}+\v{h}'^T U\v{y}}
}
{
    \sum_{\v{y}'\in\mathbb{Y}}
    \sum_{\v{h}'\in\mathbb{H}}
    \exp{\v{b}^T\v{h}'+\v{h}'^T W\v{x}+\v{c}^T\v{y}'+\v{h}'^T U\v{y}'}
}
\nonumber\\&=&
\frac{
    \prod_{i=1}^H\sum_{h'_i=0}^{1}
    \exp{b_i h'_i+h'_i \v{w}_i^T\v{x}+c_y+h'_i U_{iy}}
}
{
    \sum_{y'=1}^C
    \prod_{i=1}^H\sum_{h_i=0}^{1}
    \exp{b_i h'_i+h'_i \v{w}_i^T\v{x}+c_{y'}+h'_i U_{iy'}}
}

\\nonumber\\&=&
\frac{
    e^{c_y}\prod_{i=1}^H\left[1+
    e^{b_i+\v{w}_i^T\v{x}+U_{iy}}\right]}
}
{
    \sum_{y'=1}^C
    e^{c_{y'}}\prod_{i=1}^H\left[1+
    e^{b_i+\v{w}_i^T\v{x}+U_{iy'}}\right]}
}
\,.
end{eqnarray}
This resulting form is the discriminative classifier.

\end{document}
